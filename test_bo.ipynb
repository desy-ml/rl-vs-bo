{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing ocelot...\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from gym.wrappers import (\n",
    "    FilterObservation,\n",
    "    FlattenObservation,\n",
    "    FrameStack,\n",
    "    RecordVideo,\n",
    "    RescaleAction,\n",
    "    TimeLimit,\n",
    ")\n",
    "from stable_baselines3.common.env_util import unwrap_wrapper\n",
    "\n",
    "from bayesopt import calculate_objective, get_next_samples, scale_action, get_new_bound\n",
    "from ea_optimize import (\n",
    "    ARESEADOOCS,\n",
    "    CallbackList,\n",
    "    OptimizeFunctionCallback,\n",
    "    report_ea_optimization_to_logbook,\n",
    ")\n",
    "from utils import (\n",
    "    FilterAction,\n",
    "    NotVecNormalize,\n",
    "    PolishedDonkeyCompatibility,\n",
    "    RecordEpisode,\n",
    "    send_to_elog,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n",
    "Remarks: I would set a higher max_step for BO, maybe 100/150?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config = {\n",
    "    \"action_mode\": \"direct_unidirectional_quads\",\n",
    "    \"gamma\": 0.99,\n",
    "    # \"filter_action\": [0, 1, 3],\n",
    "    \"filter_action\": None,\n",
    "    \"filter_observation\": None,\n",
    "    \"frame_stack\": None,\n",
    "    \"incoming_mode\": \"random\",\n",
    "    \"incoming_values\": None,\n",
    "    \"magnet_init_mode\": \"constant\",\n",
    "    \"magnet_init_values\": np.array([10, -10, 0, 10, 0]),\n",
    "    \"misalignment_mode\": \"constant\",\n",
    "    \"misalignment_values\": np.zeros(8),\n",
    "    \"n_envs\": 40,\n",
    "    \"normalize_observation\": True,\n",
    "    \"normalize_reward\": True,\n",
    "    \"rescale_action\": (-3, 3),\n",
    "    \"reward_mode\": \"logl1\",\n",
    "    \"sb3_device\": \"auto\",\n",
    "    \"target_beam_mode\": \"constant\",\n",
    "    \"target_beam_values\": np.zeros(4),\n",
    "    \"target_mu_x_threshold\": 1e-5,\n",
    "    \"target_mu_y_threshold\": 1e-5,\n",
    "    \"target_sigma_x_threshold\": 1e-5,\n",
    "    \"target_sigma_y_threshold\": 1e-5,\n",
    "    \"threshold_hold\": 5,\n",
    "    \"time_limit\": 50000,\n",
    "    \"vec_env\": \"subproc\",\n",
    "    \"w_done\": 0.0,\n",
    "    \"w_mu_x\": 1.0,\n",
    "    \"w_mu_x_in_threshold\": 0.0,\n",
    "    \"w_mu_y\": 1.0,\n",
    "    \"w_mu_y_in_threshold\": 0.0,\n",
    "    \"w_on_screen\": 100.0,\n",
    "    \"w_sigma_x\": 1.0,\n",
    "    \"w_sigma_x_in_threshold\": 0.0,\n",
    "    \"w_sigma_y\": 1.0,\n",
    "    \"w_sigma_y_in_threshold\": 0.0,\n",
    "    \"w_time\": 0.0,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a similar optimize function as in ea_optimize.py\n",
    "from bayesopt import get_new_bound\n",
    "from ea_optimize import BaseCallback\n",
    "\n",
    "\n",
    "def optimize(\n",
    "    target_mu_x,\n",
    "    target_sigma_x,\n",
    "    target_mu_y,\n",
    "    target_sigma_y,\n",
    "    target_mu_x_threshold=3.3198e-6,\n",
    "    target_mu_y_threshold=3.3198e-6,\n",
    "    target_sigma_x_threshold=3.3198e-6,\n",
    "    target_sigma_y_threshold=3.3198e-6,\n",
    "    max_steps=100,\n",
    "    model_name=\"BO\",\n",
    "    logbook=False,\n",
    "    callback=BaseCallback(),\n",
    "    stepsize=0.1,  # comparable to RL env\n",
    "    obj_function=\"logmae\",\n",
    "    acquisition=\"EI\",\n",
    "    init_x=None,\n",
    "    init_samples=5,\n",
    "    filter_action=None,\n",
    "    set_to_best=True,  # set back to best found setting after opt.\n",
    "):\n",
    "    # TODO move to an init_callback function\n",
    "    if callback is None:\n",
    "        callback = BaseCallback()\n",
    "    elif isinstance(callback, list):\n",
    "        callback = CallbackList(callback)\n",
    "\n",
    "    # Create the environment\n",
    "    env = ARESEADOOCS(\n",
    "        action_mode=config[\"action_mode\"],\n",
    "        magnet_init_mode=config[\"magnet_init_mode\"],\n",
    "        magnet_init_values=config[\"magnet_init_values\"],\n",
    "        reward_mode=config[\"reward_mode\"],\n",
    "        target_beam_mode=config[\"target_beam_mode\"],\n",
    "        target_beam_values=np.array(\n",
    "            [target_mu_x, target_sigma_x, target_mu_y, target_sigma_y]\n",
    "        ),\n",
    "        target_mu_x_threshold=target_mu_x_threshold,\n",
    "        target_mu_y_threshold=target_mu_y_threshold,\n",
    "        target_sigma_x_threshold=target_sigma_x_threshold,\n",
    "        target_sigma_y_threshold=target_sigma_y_threshold,\n",
    "        threshold_hold=1,\n",
    "        w_done=config[\"w_done\"],\n",
    "        w_mu_x=config[\"w_mu_x\"],\n",
    "        w_mu_x_in_threshold=config[\"w_mu_x_in_threshold\"],\n",
    "        w_mu_y=config[\"w_mu_y\"],\n",
    "        w_mu_y_in_threshold=config[\"w_mu_y_in_threshold\"],\n",
    "        w_on_screen=config[\"w_on_screen\"],\n",
    "        w_sigma_x=config[\"w_sigma_x\"],\n",
    "        w_sigma_x_in_threshold=config[\"w_sigma_x_in_threshold\"],\n",
    "        w_sigma_y=config[\"w_sigma_y\"],\n",
    "        w_sigma_y_in_threshold=config[\"w_sigma_y_in_threshold\"],\n",
    "        w_time=config[\"w_time\"],\n",
    "    )\n",
    "    if max_steps is not None:\n",
    "        env = TimeLimit(env, max_steps)\n",
    "    if callback is not None:\n",
    "        env = OptimizeFunctionCallback(env, callback)\n",
    "    env = RecordEpisode(env)\n",
    "    if config[\"filter_observation\"] is not None:\n",
    "        env = FilterObservation(env, config[\"filter_observation\"])\n",
    "    if config[\"filter_action\"] is not None:\n",
    "        env = FilterAction(env, config[\"filter_action\"], replace=0)\n",
    "    env = FlattenObservation(env)\n",
    "    if config[\"frame_stack\"] is not None:\n",
    "        env = FrameStack(env, config[\"frame_stack\"])\n",
    "    if config[\"rescale_action\"] is not None:\n",
    "        env = RescaleAction(\n",
    "            env, config[\"rescale_action\"][0], config[\"rescale_action\"][1]\n",
    "        )\n",
    "    env = RecordVideo(env, video_folder=f\"recordings_real/{datetime.now():%Y%m%d%H%M}\")\n",
    "    # env = NotVecNormalize(env, f\"models/{model_name}/vec_normalize.pkl\")\n",
    "\n",
    "    callback.env = env\n",
    "\n",
    "    # Actual optimisation\n",
    "    t_start = datetime.now()\n",
    "    observation = env.reset()\n",
    "    beam_image_before = env.get_beam_image()\n",
    "    done = False\n",
    "\n",
    "    # Initialization\n",
    "    x_dim = env.action_space.shape[0]\n",
    "    # bounds = torch.tensor(\n",
    "    #     np.array([env.action_space.low, env.action_space.high]), dtype=torch.float32\n",
    "    # )\n",
    "    if init_x is not None:  # From fix starting points\n",
    "        X = torch.tensor(init_x.reshape(-1, x_dim), dtype=torch.float32)\n",
    "    else:  # Random Initialization-5.7934\n",
    "        action_i = scale_action(env, observation, filter_action)\n",
    "        X = torch.tensor([action_i], dtype=torch.float32)\n",
    "        bounds = get_new_bound(env, action_i, stepsize)\n",
    "        for i in range(init_samples - 1):\n",
    "            new_action = np.random.uniform(low=bounds[0], high=bounds[1])\n",
    "            X = torch.cat([X, torch.tensor([new_action])])\n",
    "    # Sample initial Ys to build GP\n",
    "    Y = torch.empty((X.shape[0], 1))\n",
    "    for i, action in enumerate(X):\n",
    "        action = action.detach().numpy()\n",
    "        print(f\"Collecting initial Ys step {i} at {action = }\")\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        print(f\"{reward = }\")\n",
    "        objective = calculate_objective(env, observation, reward, obj=obj_function)\n",
    "        Y[i] = torch.tensor(objective)\n",
    "\n",
    "    # Actual BO Loop\n",
    "    jans_i = 0\n",
    "    while not done:\n",
    "        current_action = X[-1].detach().numpy()\n",
    "        bounds = get_new_bound(env, current_action, stepsize)\n",
    "        action_t = get_next_samples(\n",
    "            X, Y, Y.max(), bounds, n_points=1, acquisition=acquisition\n",
    "        )\n",
    "        action = action_t.detach().numpy().flatten()\n",
    "        print(f\"Actual optimisation exploring step {jans_i} {action = }\")\n",
    "        jans_i += 1\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        print(f\"{reward = }\")\n",
    "        objective = calculate_objective(env, observation, reward, obj=obj_function)\n",
    "\n",
    "        # append data\n",
    "        X = torch.cat([X, action_t])\n",
    "        Y = torch.cat([Y, torch.tensor([[objective]], dtype=torch.float32)])\n",
    "\n",
    "    # Set back to \n",
    "    if set_to_best:\n",
    "        action = X[Y.argmax()].detach().numpy()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "\n",
    "    t_end = datetime.now()\n",
    "\n",
    "    recording = unwrap_wrapper(env, RecordEpisode)\n",
    "    if logbook:\n",
    "        report_ea_optimization_to_logbook(\n",
    "            model_name,\n",
    "            t_start,\n",
    "            t_end,\n",
    "            recording.observations,\n",
    "            recording.infos,\n",
    "            beam_image_before,\n",
    "            target_mu_x_threshold,\n",
    "            target_sigma_x_threshold,\n",
    "            target_mu_y_threshold,\n",
    "            target_sigma_y_threshold,\n",
    "        )\n",
    "\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting initial Ys step 0 at action = array([-2.16666651,  2.16666651,  0.        , -2.16666651,  0.        ])\n",
      "reward = -69.20180975184063\n",
      "Collecting initial Ys step 1 at action = array([-2.15454164,  1.88808345, -0.21170113, -2.01253051, -0.14593008])\n",
      "reward = -67.22633474395708\n",
      "Collecting initial Ys step 2 at action = array([-2.17611868,  2.2183891 , -0.06440592, -2.0814038 , -0.09654788])\n",
      "reward = -68.75366571387622\n",
      "Collecting initial Ys step 3 at action = array([-1.97387185,  2.40328593, -0.11946695, -1.98243373,  0.24651946])\n",
      "reward = -69.103769746625\n",
      "Collecting initial Ys step 4 at action = array([-1.92396953,  2.35696903, -0.04196954, -2.41072866,  0.19019112])\n",
      "reward = -70.77952618758502\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'isinf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# hopefully this would run :)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_mu_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 0.4249e-3,\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_sigma_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_mu_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 1.1048e-3,\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_sigma_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_mu_x_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3.16e-6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_mu_y_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3.16e-6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_sigma_x_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3.16e-6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_sigma_y_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3.16e-6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogbook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogmae\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43macquisition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEI\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [7], line 116\u001b[0m, in \u001b[0;36moptimize\u001b[0;34m(target_mu_x, target_sigma_x, target_mu_y, target_sigma_y, target_mu_x_threshold, target_mu_y_threshold, target_sigma_x_threshold, target_sigma_y_threshold, max_steps, model_name, logbook, callback, stepsize, obj_function, acquisition, init_x, init_samples, filter_action, set_to_best)\u001b[0m\n\u001b[1;32m    114\u001b[0m current_action \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    115\u001b[0m bounds \u001b[38;5;241m=\u001b[39m get_new_bound(env, current_action, stepsize)\n\u001b[0;32m--> 116\u001b[0m action_t \u001b[38;5;241m=\u001b[39m \u001b[43mget_next_samples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macquisition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macquisition\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m action \u001b[38;5;241m=\u001b[39m action_t\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActual optimisation exploring step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjans_i\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction \u001b[38;5;132;01m= }\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/DESY/ares-ea-rl/bayesopt.py:139\u001b[0m, in \u001b[0;36mget_next_samples\u001b[0;34m(X, Y, best_y, bounds, n_points, acquisition)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39melif\u001b[39;00m acquisition \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mUCB\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    137\u001b[0m     acq \u001b[39m=\u001b[39m UpperConfidenceBound(gp, beta\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m candidates, _ \u001b[39m=\u001b[39m optimize_acqf(\n\u001b[1;32m    140\u001b[0m     acq_function\u001b[39m=\u001b[39;49macq,\n\u001b[1;32m    141\u001b[0m     bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[1;32m    142\u001b[0m     q\u001b[39m=\u001b[39;49mn_points,\n\u001b[1;32m    143\u001b[0m     num_restarts\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m,\n\u001b[1;32m    144\u001b[0m     raw_samples\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,\n\u001b[1;32m    145\u001b[0m     options\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mmaxiter\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m200\u001b[39;49m},\n\u001b[1;32m    146\u001b[0m )\n\u001b[1;32m    148\u001b[0m \u001b[39mreturn\u001b[39;00m candidates\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/rl39/lib/python3.9/site-packages/botorch/optim/optimize.py:230\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, sequential, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m batch_initial_conditions\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m initial_conditions_provided:\n\u001b[0;32m--> 230\u001b[0m     batch_initial_conditions \u001b[39m=\u001b[39m _gen_initial_conditions()\n\u001b[1;32m    232\u001b[0m batch_limit: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m options\u001b[39m.\u001b[39mget(\n\u001b[1;32m    233\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbatch_limit\u001b[39m\u001b[39m\"\u001b[39m, num_restarts \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nonlinear_inequality_constraints \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    236\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_optimize_batch_candidates\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tensor, Tensor, List[\u001b[39mWarning\u001b[39;00m]]:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/rl39/lib/python3.9/site-packages/botorch/optim/optimize.py:216\u001b[0m, in \u001b[0;36moptimize_acqf.<locals>._gen_initial_conditions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_gen_initial_conditions\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    211\u001b[0m     ic_gen \u001b[39m=\u001b[39m (\n\u001b[1;32m    212\u001b[0m         gen_one_shot_kg_initial_conditions\n\u001b[1;32m    213\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(acq_function, qKnowledgeGradient)\n\u001b[1;32m    214\u001b[0m         \u001b[39melse\u001b[39;00m gen_batch_initial_conditions\n\u001b[1;32m    215\u001b[0m     )\n\u001b[0;32m--> 216\u001b[0m     batch_initial_conditions \u001b[39m=\u001b[39m ic_gen(\n\u001b[1;32m    217\u001b[0m         acq_function\u001b[39m=\u001b[39;49macq_function,\n\u001b[1;32m    218\u001b[0m         bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[1;32m    219\u001b[0m         q\u001b[39m=\u001b[39;49mq,\n\u001b[1;32m    220\u001b[0m         num_restarts\u001b[39m=\u001b[39;49mnum_restarts,\n\u001b[1;32m    221\u001b[0m         raw_samples\u001b[39m=\u001b[39;49mraw_samples,\n\u001b[1;32m    222\u001b[0m         fixed_features\u001b[39m=\u001b[39;49mfixed_features,\n\u001b[1;32m    223\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    224\u001b[0m         inequality_constraints\u001b[39m=\u001b[39;49minequality_constraints,\n\u001b[1;32m    225\u001b[0m         equality_constraints\u001b[39m=\u001b[39;49mequality_constraints,\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m batch_initial_conditions\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/rl39/lib/python3.9/site-packages/botorch/optim/initializers.py:101\u001b[0m, in \u001b[0;36mgen_batch_initial_conditions\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, fixed_features, options, inequality_constraints, equality_constraints)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgen_batch_initial_conditions\u001b[39m(\n\u001b[1;32m     51\u001b[0m     acq_function: AcquisitionFunction,\n\u001b[1;32m     52\u001b[0m     bounds: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m     equality_constraints: Optional[List[Tuple[Tensor, Tensor, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     60\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m     61\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Generate a batch of initial conditions for random-restart optimziation.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \n\u001b[1;32m     63\u001b[0m \u001b[39m    TODO: Support t-batches of initial conditions.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39m        >>> )\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     \u001b[39mif\u001b[39;00m bounds\u001b[39m.\u001b[39;49misinf()\u001b[39m.\u001b[39many():\n\u001b[1;32m    102\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    103\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCurrently only finite values in `bounds` are supported \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mfor generating initial conditions for optimization.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m         )\n\u001b[1;32m    106\u001b[0m     options \u001b[39m=\u001b[39m options \u001b[39mor\u001b[39;00m {}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'isinf'"
     ]
    }
   ],
   "source": [
    "# hopefully this would run :)\n",
    "\n",
    "optimize(\n",
    "    target_mu_x=0.0,    # 0.4249e-3,\n",
    "    target_sigma_x=0.0,\n",
    "    target_mu_y=0.0,    # 1.1048e-3,\n",
    "    target_sigma_y=0.0,\n",
    "    target_mu_x_threshold=3.16e-6,\n",
    "    target_mu_y_threshold=3.16e-6,\n",
    "    target_sigma_x_threshold=3.16e-6,\n",
    "    target_sigma_y_threshold=3.16e-6,\n",
    "    max_steps=10,\n",
    "    model_name=\"BO\",\n",
    "    logbook=True,\n",
    "    callback=None,\n",
    "    obj_function=\"logmae\",\n",
    "    acquisition=\"EI\",\n",
    "    init_x=None,\n",
    "    init_samples=5,\n",
    "    filter_action=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hopefully this would run :)\n",
    "\n",
    "# optimize(\n",
    "#     target_mu_x=0.4249e-3,\n",
    "#     target_sigma_x=0.0,\n",
    "#     target_mu_y=1.1048e-3,\n",
    "#     target_sigma_y=0.0,\n",
    "#     target_mu_x_threshold=3.16e-6,\n",
    "#     target_mu_y_threshold=3.16e-6,\n",
    "#     target_sigma_x_threshold=3.16e-6,\n",
    "#     target_sigma_y_threshold=3.16e-6,\n",
    "#     max_steps=100,\n",
    "#     model_name=\"BO\",\n",
    "#     logbook=True,\n",
    "#     callback=None,\n",
    "#     obj_function='logmae',\n",
    "#     acquisition=\"EI\",\n",
    "#     init_x = None,\n",
    "#     init_samples = 5,\n",
    "#     filter_action = None,\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('rl39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "343fe3b89e2d7877d61a0509fd880204236e5c07449e4c121f53f2530ef83fc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
