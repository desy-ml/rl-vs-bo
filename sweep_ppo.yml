name: PPO Sweep
project: ares-ea-rl
entity: msk-ipc
program: train_ppo.py
command:
  - ${env}
  - python3
  - ${program}
  - ${args}
method: random
metric:
  goal: maximize
  name: eval/mean_reward
parameters:
  learning_rate:
    values: [0.00003, 0.0003, 0.003]
  batch_size:
    values: [32, 64, 256]
  gae_lambda:
    values: [0.9, 0.98, 0.999]
  gamma:
    values: [0.9, 0.99, 0.999]
  clip_range:
    values: [0.2, 0.5, 1.0]
  ent_coef:
    values: [0.0, 0.2, 0.4]
  vf_coef:
    values: [0.1, 0.5, 1.0]
  max_grad:norm:
    values: [0.2, 0.5, 0.8]
  net_arch:
    values: [[32,32], [400,300], [800,600]]
