{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing ocelot...\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from gym.wrappers import RescaleAction, TimeLimit\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from tqdm import tqdm\n",
    "\n",
    "from environments import ARESEASequential, ResetActuators, ResetActuatorsToDFD\n",
    "import toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging (to console)\n",
    "timestamp = lambda: datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)-7.7s: %(message)s\")\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "path = os.getcwd() # Check path and directory before running\n",
    "folder = 'logs'\n",
    "Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "directory = os.path.join(path, folder)\n",
    "description  = 'evaluate_machine'\n",
    "logpath = os.path.join(directory,f'{timestamp()}_{description}.log')\n",
    "\n",
    "file_handler = logging.FileHandler(logpath)\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)-7.7s: %(message)s\")\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequential(model_name, max_episode_steps=30, measure_beam=\"us\", init=\"dfd\"):\n",
    "\n",
    "    ModelSetup = namedtuple(\"ModelSetup\", [\"name\",\"env\",\"model\",\"max_episode_steps\",\"measure_beam\"])\n",
    "\n",
    "    log_dir = f\"models/{model_name}\"\n",
    "\n",
    "    def make_env():\n",
    "        env = ARESEASequential(\n",
    "            backend=\"machine\",\n",
    "            backendargs={\"measure_beam\": measure_beam}\n",
    "        )\n",
    "        if init == \"dfd\":\n",
    "            env = ResetActuatorsToDFD(env, k1=10)\n",
    "        elif init == \"zero\":\n",
    "            env = ResetActuators(env)\n",
    "        elif init == \"random\":\n",
    "            pass\n",
    "        env = TimeLimit(env, max_episode_steps=max_episode_steps)\n",
    "        env = RescaleAction(env, -1, 1)\n",
    "        return env\n",
    "\n",
    "    env = DummyVecEnv([make_env])\n",
    "    env = VecNormalize.load(f\"{log_dir}/vec_normalize.pkl\", env)\n",
    "    env.training = False\n",
    "    env.norm_reward = False\n",
    "\n",
    "    model = TD3.load(f\"{log_dir}/model\")\n",
    "\n",
    "    return ModelSetup(model_name, env, model, max_episode_steps, measure_beam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_dataframe(fn):\n",
    "    def wrapper(setup, problem):\n",
    "        observations, rewards, beam_images = fn(setup, problem)\n",
    "        observations = np.array(observations)\n",
    "\n",
    "        df = pd.DataFrame(np.arange(len(observations)), columns=[\"step\"])\n",
    "        df[\"q1\"] = observations[:,0]\n",
    "        df[\"q2\"] = observations[:,1]\n",
    "        df[\"cv\"] = observations[:,2]\n",
    "        df[\"q3\"] = observations[:,3]\n",
    "        df[\"ch\"] = observations[:,4]\n",
    "        df[\"mup_x\"] = observations[:,5]\n",
    "        df[\"mup_y\"] = observations[:,6]\n",
    "        df[\"sigmap_x\"] = observations[:,7]\n",
    "        df[\"sigmap_y\"] = observations[:,8]\n",
    "        df[\"mu_x\"] = observations[:,9]\n",
    "        df[\"mu_y\"] = observations[:,10]\n",
    "        df[\"sigma_x\"] = observations[:,11]\n",
    "        df[\"sigma_y\"] = observations[:,12]\n",
    "        df[\"reward\"] = [np.nan] + rewards\n",
    "        df[\"beam_image\"] = beam_images\n",
    "\n",
    "        df[\"model_name\"] = setup.name\n",
    "        df[\"max_episode_steps\"] = setup.max_episode_steps\n",
    "        df[\"measure_beam\"] = setup.measure_beam\n",
    "\n",
    "        return df\n",
    "    \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pack_dataframe\n",
    "def run(setup, problem):\n",
    "    env, model = setup.env, setup.model\n",
    "\n",
    "    if \"initial\" in problem:\n",
    "        env.get_attr(\"unwrapped\")[0].next_initial = problem[\"initial\"]\n",
    "    if \"desired\" in problem:\n",
    "        env.get_attr(\"unwrapped\")[0].next_desired = problem[\"desired\"]\n",
    "\n",
    "    observations = []\n",
    "    rewards = []\n",
    "    beam_images = []\n",
    "\n",
    "    observation = env.reset()\n",
    "    observations.append(env.unnormalize_obs(observation).squeeze())\n",
    "    beam_images.append(env.get_attr(\"backend\")[0].last_beam_image)\n",
    "\n",
    "    env.get_attr(\"unwrapped\")[0].next_initial = \"stay\"\n",
    "\n",
    "    with tqdm(total=setup.max_episode_steps) as pbar:\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = model.predict(observation, deterministic=True)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "\n",
    "            observations.append(env.unnormalize_obs(observation).squeeze())\n",
    "            rewards.append(reward.squeeze())\n",
    "            beam_images.append(env.get_attr(\"backend\")[0].last_beam_image)\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    observations[-1] = env.unnormalize_obs(info[0][\"terminal_observation\"].squeeze())\n",
    "\n",
    "    return observations, rewards, beam_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_name, directory, method=None, description=None, init=\"dfd\", n=None):\n",
    "    setup = load_sequential(model_name, init=init)\n",
    "\n",
    "    with open(\"problems_3.json\", \"r\") as f:\n",
    "        if isinstance(n, int):            \n",
    "            problems = json.load(f) if n is None else json.load(f)[:n]\n",
    "        elif isinstance(n, tuple):\n",
    "            problems = json.load(f) if n is None else json.load(f)[n[0]:n[1]]\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for i, problem in enumerate(tqdm(problems)):\n",
    "        logger.info(f\"Agent {model_name} running problem {i}:\\n  Desired = {problem['desired']}\")\n",
    "        \n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        result = run(setup, problem=problem)\n",
    "        result[\"problem\"] = i\n",
    "        result[\"model\"] = setup.name\n",
    "        if method is not None:\n",
    "            result[\"method\"] = method\n",
    "        if description is not None:\n",
    "            result[\"description\"] = description\n",
    "        result.to_pickle(f\"{directory}/{model_name}_{i:03d}_{timestamp}.pkl\")\n",
    "        \n",
    "        toolkit.send_mail(\n",
    "            f\"MSK-IPC AA: Agent {model_name} finished running problem {i}\",\n",
    "            [\"oliver.stein@desy.de\",\"jan.kaiser@desy.de\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Running is Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                               | 0/278 [00:00<?, ?it/s]2021-11-25 17:55:22,540 - INFO   : Agent polished-donkey-996 running problem 0:\n",
      "  Desired = [-0.001, 0.001, 0.0005, 0.0]\n",
      "\n",
      "  0%|                                                                                                                | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|███▍                                                                                                    | 1/30 [00:08<04:11,  8.66s/it]\u001b[A\n",
      "  7%|██████▉                                                                                                 | 2/30 [00:17<03:58,  8.50s/it]\u001b[A\n",
      " 10%|██████████▍                                                                                             | 3/30 [00:24<03:35,  8.00s/it]\u001b[A\n",
      " 13%|█████████████▊                                                                                          | 4/30 [00:31<03:21,  7.76s/it]\u001b[A\n",
      " 17%|█████████████████▎                                                                                      | 5/30 [00:39<03:10,  7.63s/it]\u001b[A\n",
      " 20%|████████████████████▊                                                                                   | 6/30 [00:46<03:01,  7.55s/it]\u001b[A\n",
      " 23%|████████████████████████▎                                                                               | 7/30 [00:54<02:52,  7.51s/it]\u001b[A\n",
      " 27%|███████████████████████████▋                                                                            | 8/30 [01:01<02:44,  7.48s/it]\u001b[A\n",
      " 30%|███████████████████████████████▏                                                                        | 9/30 [01:58<08:05, 23.10s/it]\u001b[A\n",
      " 33%|██████████████████████████████████▎                                                                    | 10/30 [02:06<06:05, 18.25s/it]\u001b[A\n",
      " 37%|█████████████████████████████████████▊                                                                 | 11/30 [02:13<04:43, 14.93s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "n = (22, 300)\n",
    "directory = \"machine_studies/next_to_27_polished_donkey\"\n",
    "todo = {\n",
    "    \"method\": \"resettodfd\",\n",
    "    \"description\": \"Reset to DFD (with Adjusted Initial)\",\n",
    "    \"models\": [\"polished-donkey-996\"], # , \"polar-lake-997\", \"still-deluge-998\"],\n",
    "    \"init\": \"dfd\"\n",
    "}\n",
    "\n",
    "for model in todo[\"models\"]:\n",
    "    evaluate(\n",
    "        model,\n",
    "        directory,\n",
    "        method=todo[\"method\"],\n",
    "        description=todo[\"description\"],\n",
    "        init=todo[\"init\"],\n",
    "        n=n\n",
    "    )\n",
    "toolkit.send_mail(\n",
    "    f\"MSK-IPC AA: The polished donkey has finished. It's very shiny now.\",\n",
    "    [\"oliver.stein@desy.de\",\"jan.kaiser@desy.de\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb0c3e2128e3ec31ec0d90a83c3ce95af788e3d47340cfb20bbf06ca38505d8f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
